\documentclass[runningheads]{llncs}
\usepackage[T5]{fontenc}
% \usepackage{graphicx}
\usepackage{hyperref}
\usepackage{color}
\renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}
%
\title{Minimal trap-spaces of Logical models are maximal siphons of their Petri-net encoding}
\titlerunning{Minimal trap-spaces as maximal siphons}
\author{Van-Giang Trịnh\inst{1}\orcidID{0000-0001-6581-998X} \and \\
  Sylvain Soliman\inst{2}\orcidID{0000-0001-5525-7418}}
% \authorrunning{F. Author et al.}

\institute{
  Aix-Marseille Université, Marseille, France\\
  \email{Trinh.Van-Giang@lis-lab.fr}
  \and
  Lifeware team, Inria Saclay center, Palaiseau, France\\
  \email{Sylvain.Soliman@inria.fr}%\\
  %\url{http://lifeware.inria.fr/~soliman/}
}

\maketitle

\begin{abstract}
  % The abstract should briefly summarize the contents of the paper in
  % 150--250 words.

  Discrete modelling has proven over the years that it can bring powerful analyses and corresponding insight to the many cases where precise biological data is not sufficiently available to build a detailed quantitative model.
  This is even more true for very big models where such data is frequently missing and led to a constant increase in size of logical models \emph{à la} Thomas.
  The analysis of such models is mostly based on attractor computation, since those correspond roughly to \emph{phenotypes}, and the recent use of trap-spaces made a real breakthrough in that domain allowing to consider medium-sized models that used to be out of reach.
  However, with the continuing increase in model-size, the state of the art computation of minimal trap-spaces based on prime-implicants shows its limits as there can be very many such implicants.
  In this article we present an alternative method to compute minimal trap-spaces, and hence complex attractors, that relies on a completely different technique, namely the enumeration of maximal siphons in the Petri-net encoding of the original Logical model.
  We then demonstrate its efficiency and compare it to implicant-based methods on a few relevant big Boolean models.

\keywords{Logical models \and Boolean models \and Trap-spaces \and Attractor computation \and Petri-nets \and Siphons}
\end{abstract}

\section{Introduction}

Discrete modelling has proven over the years that it can bring powerful analyses and corresponding insight to the many cases where precise biological data is not sufficiently available to build a detailed quantitative model.
This is even more true for very big models where such data is frequently missing and led to a constant increase in size of logical models \emph{à la} Thomas.
The analysis of such models is mostly based on attractor computation, since those correspond roughly to \emph{phenotypes}, and the recent use of trap-spaces made a real breakthrough in that domain allowing to consider medium-sized models that used to be out of reach.
However, with the continuing increase in model-size, the state of the art computation of minimal trap-spaces based on prime-implicants shows its limits as there can be very many such implicants.
In this article we present an alternative method to compute minimal trap-spaces, and hence complex attractors, that relies on a completely different technique, namely the enumeration of maximal siphons in the Petri-net encoding of the original Logical model.
We then demonstrate its efficiency and compare it to implicant-based methods on a few relevant big Boolean models.

\section{Minimal trap-spaces as maximal siphons}
\subsection{Preliminaries}
\subsubsection{Traps-spaces}

\cite{klarner2015computing,klarner2017pyboolnet,cifuentes2020control}

\subsubsection{Petri-net encoding of Logical models}

Original encoding~\cite{chaouiya2004qualitative,chaouiya2011petri} vs. more recent one~\cite{chatain2014characterization}.
All identical on Boolean models?

\subsubsection{Siphons}

\subsection{New method}

SBML-Qual~\cite{chaouiya2013sbml}/BoolNet~\cite{mussel2010boolnet,klarner2017pyboolnet} to PNML\footnote{\url{https://www.pnml.org/}} works via GINsim~\cite{chaouiya2012logical}/BioLQM\footnote{http://www.colomoto.org/biolqm/} with
\begin{verbatim}
java -jar GINsim.jar -lqm <input.sbml/input.bnet> <output.pnml>
\end{verbatim}

\section{Evaluation}
\subsection{Benchmark vs. implicant-based methods}

\url{http://colomoto.org/biolqm/doc/tools-trapspace.html}

\subsection{Detailed biological example}

TBD

\section{Conclusion}

\subsubsection{Acknowledgments}
Coffee is good, you should drink some!

\bibliographystyle{splncs04}
\bibliography{cmsb22.bib}

\end{document}

% \begin{table}
% \caption{Table captions should be placed above the
% tables.}\label{tab1}
% \begin{tabular}{|l|l|l|}
% \hline
% Heading level &  Example & Font size and style\\
% \hline
% Title (centered) &  {\Large\bfseries Lecture Notes} & 14 point, bold\\
% 1st-level heading &  {\large\bfseries 1 Introduction} & 12 point, bold\\
% 2nd-level heading & {\bfseries 2.1 Printing Area} & 10 point, bold\\
% 3rd-level heading & {\bfseries Run-in Heading in Bold.} Text follows & 10 point, bold\\
% 4th-level heading & {\itshape Lowest Level Heading.} Text follows & 10 point, italic\\
% \hline
% \end{tabular}
% \end{table}


% \noindent Displayed equations are centered and set on a separate
% line.
% \begin{equation}
% x + y = z
% \end{equation}
% Please try to avoid rasterized images for line-art diagrams and
% schemas. Whenever possible, use vector graphics instead (see
% Fig.~\ref{fig1}).

% \begin{figure}
% % \includegraphics[width=\textwidth]{fig1.eps}
% \caption{A figure caption is always placed below the illustration.
% Please note that short captions are centered, while long ones are
% justified by the macro package automatically.} \label{fig1}
% \end{figure}

% \begin{theorem}
% This is a sample theorem. The run-in heading is set in bold, while
% the following text appears in italics. Definitions, lemmas,
% propositions, and corollaries are styled the same way.
% \end{theorem}
% %
% % the environments 'definition', 'lemma', 'proposition', 'corollary',
% % 'remark', and 'example' are defined in the LLNCS documentclass as well.
% %
% \begin{proof}
% Proofs, examples, and remarks have the initial word in italics,
% while the following text appears in normal font.
% \end{proof}
